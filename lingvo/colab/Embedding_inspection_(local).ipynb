{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcYJIEwd3As"
      },
      "source": [
        "#### local run command\n",
        "`blaze run -c opt learning/brain/research/babelfish/colab:colab_notebook --define=babelfish_task=multimodal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7ZcyyqZKJi"
      },
      "outputs": [],
      "source": [
        "import lingvo.compat as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from lingvo.core import py_utils\n",
        "from google3.learning.brain.research.babelfish import tokenizers\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_baselines as it_params\n",
        "\n",
        "# from google3.pyglib import gfiler\n",
        "\n",
        "from google3.perftools.accelerators.xprof.api.colab import xprof\n",
        "\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFau_Ds6267r"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZujlTGZZlK"
      },
      "outputs": [],
      "source": [
        "mdl_it2t = it_params.ImageText2TextLMSmall()\n",
        "mdl_t2t = it_params.Text2TextLMSmall()\n",
        "mdl_t2t_twin = it_params.Text2TextLMSmall()\n",
        "\n",
        "p_it2t = mdl_it2t.Task()\n",
        "p_t2t = mdl_t2t.Task()\n",
        "p_t2t_twin = mdl_t2t_twin.Task()\n",
        "\n",
        "# Note: We use the name as part of var/name scopes, you need to ensure that\n",
        "# the name here matches for checkpoints to load successfully.\n",
        "\n",
        "p_it2t.name = 'ImageText2TextLMTask'\n",
        "p_t2t.name = 'Text2TextLM'\n",
        "p_t2t_twin.name = 'Text2TextLM_Twin'\n",
        "p_it2t.input = mdl_it2t.Train()\n",
        "p_t2t.input = mdl_t2t.Train()\n",
        "p_t2t_twin.input = mdl_t2t_twin.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CafizIxXQfa"
      },
      "outputs": [],
      "source": [
        "# We are going to use the global graph for this entire colab.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the Task.\n",
        "task_it2t = p_it2t.Instantiate()\n",
        "task_t2t = p_t2t.Instantiate()\n",
        "task_t2t_twin = p_t2t_twin.Instantiate()\n",
        "\n",
        "# Create variables by running FProp.\n",
        "_ = task_it2t.FPropDefaultTheta()\n",
        "_ = task_t2t.FPropDefaultTheta()\n",
        "_ = task_t2t_twin.FPropDefaultTheta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcdhCnAGprFr"
      },
      "outputs": [],
      "source": [
        "# Create a new session and initialize all the variables.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCpH22KqYgVQ"
      },
      "outputs": [],
      "source": [
        "# Setup the checkpoint loading rules for OverrideVarsFromCheckpoints.\n",
        "loading_rules = [\n",
        "    (\n",
        "        \"(.*)\",  # Regexp match all variables in the ckpt.\n",
        "        \"%s\"     # Format string to use the saved var name as is.\n",
        "    )\n",
        "]\n",
        "loading_rules_twin = [\n",
        "    (\n",
        "        \"Text2TextLM_Twin/(.*/var:0$)\",  \n",
        "        \"Text2TextLM/%s\"    \n",
        "    )\n",
        "]\n",
        "\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "\n",
        "ckpts_loading_rules = lambda x, y:{\n",
        "    x: (y, ignore_rules)\n",
        "}\n",
        "\n",
        "# ckpt_path_it2t = '/cns/jn-d/home/ziruiw/brain/rs=6.3/ImageText2TextLM.small.ibz4096.tbz512.PrefixLM.Res50.Trans2.BatchMajor.RelPos.LR5e4.WD1e2/train/ckpt-01000000'\n",
        "ckpt_path_t2t = '/cns/tp-d/home/runzheyang/brain/rs=6.3/text2textlm.small.fixedtranspose.1/train/ckpt-01000000'\n",
        "ckpt_path_t2t_twin = '/cns/tp-d/home/runzheyang/brain/rs=6.3/text2textlm.small.fixedtranspose.1.twin/train/ckpt-01000000'\n",
        "ckpt_path_it2t = '/cns/mb-d/home/yuancao/brain/rs=6.3/mm_it2t_10_0.5/train/ckpt-00759000'\n",
        "\n",
        "\n",
        "# Load the saved checkpoint into the session.\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_it2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_it2t, loading_rules))(sess)\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_t2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_t2t, loading_rules))(sess)\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_t2t_twin.name+\"//*\"), ckpts_loading_rules(ckpt_path_t2t_twin, loading_rules_twin))(sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmKbE6-5DkN4"
      },
      "source": [
        "### Load top 5000 frequent words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpVjYew3u1RU"
      },
      "outputs": [],
      "source": [
        "from google3.pyglib import gfile\n",
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/5000-words.txt', 'r') as f:\n",
        "  freq_words = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn9_kRol2Pct"
      },
      "outputs": [],
      "source": [
        "input_p = mdl_t2t.Train()\n",
        "input_gen = input_p.Instantiate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "divXII6i8kA5"
      },
      "outputs": [],
      "source": [
        "freq_ids = input_gen._vocabulary._encode(freq_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaSZWPEeG5cl"
      },
      "outputs": [],
      "source": [
        "freq_ids = np.unique(freq_ids)\n",
        "freq_ids = [int(i) for i in freq_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4zdWIqaCgup"
      },
      "outputs": [],
      "source": [
        "input_gen._vocabulary._decode(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJzqXdtEC0NE"
      },
      "outputs": [],
      "source": [
        "len(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKq6N3QcDDcL"
      },
      "outputs": [],
      "source": [
        "# get token embedding (w/o positional embedding), assuming share_emd=True.\n",
        "it2t_token_embeddings = task_it2t.encoder.softmax.EmbLookup(\n",
        "    task_it2t.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "t2t_token_embeddings = task_t2t.encoder.softmax.EmbLookup(\n",
        "    task_t2t.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "t2t_twin_token_embeddings = task_t2t_twin.encoder.softmax.EmbLookup(\n",
        "    task_t2t_twin.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "fetches = py_utils.NestedMap({\n",
        "    \"it2t_emb\": it2t_token_embeddings,\n",
        "    \"t2t_emb\": t2t_token_embeddings,\n",
        "    \"t2t_twin_emb\": t2t_twin_token_embeddings\n",
        "})\n",
        "\n",
        "print(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twMbz_cyDZhD"
      },
      "outputs": [],
      "source": [
        "emb_output = sess.run(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpLY7b2Z-km0"
      },
      "outputs": [],
      "source": [
        "it2t_emb = emb_output[\"it2t_emb\"]\n",
        "t2t_emb = emb_output[\"t2t_emb\"]\n",
        "t2t_twin_emb = emb_output[\"t2t_twin_emb\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsGOoa80XFT"
      },
      "outputs": [],
      "source": [
        "def cos_similarity(vecs):\n",
        "  dotp = vecs.dot(vecs.T)\n",
        "  norm = np.sqrt((vecs ** 2).sum(1))\n",
        "  length = np.outer(norm, norm)\n",
        "  return dotp / length - np.eye(len(vecs))\n",
        "\n",
        "def k_nn(sim_matrix, k=-1):\n",
        "  return np.argsort(sim_matrix, -1)[:,::-1][:, :k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzWKP-TQC2cC"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_it2t = cos_similarity(it2t_emb)\n",
        "knn_it2t_10 = k_nn(sim_matrix_it2t, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJvuoGQFEJff"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_t2t = cos_similarity(t2t_emb)\n",
        "knn_t2t_10 = k_nn(sim_matrix_t2t, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7Pv6NPMEMcw"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_t2t_twin = cos_similarity(t2t_twin_emb)\n",
        "knn_t2t_twin_10 = k_nn(sim_matrix_t2t_twin, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWx_q3S1RVyP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# obtain top 5 similar words\n",
        "knn_it2t_5 = k_nn(sim_matrix_it2t, 5)\n",
        "knn_t2t_5 = k_nn(sim_matrix_t2t, 5)\n",
        "knn_t2t_twin_5 = k_nn(sim_matrix_t2t_twin, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmzpY3cWD2V3"
      },
      "outputs": [],
      "source": [
        "knn_it2t_10.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnNqTUmAD38F"
      },
      "outputs": [],
      "source": [
        "knn_t2t_twin_10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8vdcN6BKqN_"
      },
      "source": [
        "### Check nearest words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVNOy37XEUX0"
      },
      "outputs": [],
      "source": [
        "def check_id(rid, freq_ids, knn):\n",
        "  print(\"query:\", input_gen._vocabulary._decode([int(freq_ids[rid])]))\n",
        "  print(\"similar words:\", [input_gen._vocabulary._decode([int(freq_ids[i])])  for i in knn[rid]])\n",
        "\n",
        "def check_word(word, freq_ids, knn):\n",
        "  wids = input_gen._vocabulary._encode(word)\n",
        "  for wid in wids:\n",
        "    # skip the empty token..\n",
        "    if wid == 3: continue\n",
        "    rid = freq_ids.index(wid)\n",
        "    check_id(rid, freq_ids, knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADKbpGQdE8Lz"
      },
      "outputs": [],
      "source": [
        "query = 'cat'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pl0YiduJgwB"
      },
      "outputs": [],
      "source": [
        "query = 'dream'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L3LPMSx8M2K"
      },
      "outputs": [],
      "source": [
        "np.intersect1d(['fantasy', 'imagine', 'passion', 'vision', 'desire', 'delight', 'ambition', 'imagination', 'miracle', 'wish'], \n",
        "                ['nightmare', 'vision', 'imagine', 'envision', 'imagination', 'fantasy', 'desire', 'wish', 'joy', 'wake'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl8zsTPgJoJX"
      },
      "outputs": [],
      "source": [
        "query = 'throw'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8SEGl8OKMld"
      },
      "outputs": [],
      "source": [
        "query = 'sing'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKShf-KhKkEL"
      },
      "outputs": [],
      "source": [
        "query = 'compromise'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkSmS65ANfiR"
      },
      "source": [
        "### Quantitive comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hDdZV4VLH6E"
      },
      "outputs": [],
      "source": [
        "def diff_scores(knn1, knn2, k):\n",
        "  return [len(np.intersect1d(knn1[i], knn2[i]))/k for i in range(len(knn1))] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii_YLZwjNrh5"
      },
      "outputs": [],
      "source": [
        "top_k = 10\n",
        "it2t_vs_t2t = diff_scores(k_nn(sim_matrix_it2t, top_k), k_nn(sim_matrix_t2t, top_k), top_k)\n",
        "np.mean(it2t_vs_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lRDOCsAONkv"
      },
      "outputs": [],
      "source": [
        "t2t_vs_t2t = diff_scores(k_nn(sim_matrix_t2t, top_k), k_nn(sim_matrix_t2t_twin, top_k), top_k)\n",
        "np.mean(t2t_vs_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlBdhS28Ppkl"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set_context('talk')\n",
        "\n",
        "distplot = lambda x, c, l: sns.distplot(x, kde=False,\n",
        "                            hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
        "                            \"alpha\": 0.8, \"color\": c, \"label\": l})\n",
        "\n",
        "distplot(it2t_vs_t2t, 'g', 'it2t vs t2t')\n",
        "distplot(t2t_vs_t2t, 'orange', 't2t vs t2t')\n",
        "plt.xlabel(\"top 10 nearest neighbor coherence\")\n",
        "plt.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wz5iXQJOPX8"
      },
      "outputs": [],
      "source": [
        "def id2word(rid):\n",
        "  return(input_gen._vocabulary._decode([int(freq_ids[rid])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qda1r-N4OjN_"
      },
      "outputs": [],
      "source": [
        "# most dissimilar words (it2t vs t2t)\n",
        "np.vectorize(id2word)(np.argsort(it2t_vs_t2t))[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Air-2b3NPJXr"
      },
      "outputs": [],
      "source": [
        "# most similar words (it2t vs t2t)\n",
        "np.vectorize(id2word)(np.argsort(it2t_vs_t2t))[-30:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PedDQddPLHk"
      },
      "outputs": [],
      "source": [
        "query = 'abstract'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6OwpQGnPYCa"
      },
      "outputs": [],
      "source": [
        "# most dissimilar words (t2t vs t2t)\n",
        "np.vectorize(id2word)(np.argsort(t2t_vs_t2t))[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sVZhX97TqcA"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def r2(x, y):\n",
        "    return stats.pearsonr(x, y)[0] ** 2\n",
        "\n",
        "sns.regplot(t2t_vs_t2t, it2t_vs_t2t)\n",
        "plt.xlabel(\"t2t vs t2t\")\n",
        "plt.ylabel(\"it2t vs t2t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_nPUcc_4gta"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def r2(x, y):\n",
        "    return stats.pearsonr(x, y)[0] ** 2\n",
        "\n",
        "r2(it2t_vs_t2t, t2t_vs_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPiXWYpq5Ohg"
      },
      "outputs": [],
      "source": [
        "hard_words = np.arange(len(freq_ids))[(np.array(it2t_vs_t2t) \u003c 0.3) \u0026 (np.array(t2t_vs_t2t) \u003c 0.3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWGB6J7S5jEo"
      },
      "outputs": [],
      "source": [
        "np.vectorize(id2word)(hard_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr6KxGsP7cD6"
      },
      "outputs": [],
      "source": [
        "easy_words = np.arange(len(freq_ids))[(np.array(it2t_vs_t2t) \u003e 0.8) \u0026 (np.array(t2t_vs_t2t) \u003e 0.8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itEczqjv7d90"
      },
      "outputs": [],
      "source": [
        "np.vectorize(id2word)(easy_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEvCO7b58X3S"
      },
      "outputs": [],
      "source": [
        "query = 'decrease'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvWmyf4mHd9D"
      },
      "outputs": [],
      "source": [
        "query = 'traditional'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVUGAY5g76JX"
      },
      "source": [
        "## Compare Concreteness Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhfD7T5eDlSz"
      },
      "outputs": [],
      "source": [
        "from google3.pyglib import gfile\n",
        "\n",
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/concreteness.xlsx', 'rb') as fh:  \n",
        "  concrete_scores = pd.read_excel(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrzvytHSEYW9"
      },
      "outputs": [],
      "source": [
        "concrete_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xoIeVREFQQ6"
      },
      "outputs": [],
      "source": [
        "bool_wordpiece = []\n",
        "for i, w in enumerate(list(concrete_scores[\"Word\"])):\n",
        "  ids = input_gen._vocabulary.encode(str(w))\n",
        "  bool_wordpiece.append(len(ids) == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7g1tYWtIL4z"
      },
      "outputs": [],
      "source": [
        "concrete_scores['is_wordpiece'] = bool_wordpiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqy-AqqGR2uQ"
      },
      "outputs": [],
      "source": [
        "concrete_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO_VPygeUgY7"
      },
      "outputs": [],
      "source": [
        "cr_wid = [input_gen._vocabulary.encode(w) for w in concrete_scores[\"Word\"][concrete_scores[\"is_wordpiece\"]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2drAGsjMUyEp"
      },
      "outputs": [],
      "source": [
        "cr_wid = np.array(cr_wid).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYKmFYgvVTeF"
      },
      "outputs": [],
      "source": [
        "len(np.intersect1d(cr_wid, freq_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKryZfGLWCA4"
      },
      "outputs": [],
      "source": [
        "len(np.union1d(cr_wid, freq_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4DwJ-fDVePA"
      },
      "outputs": [],
      "source": [
        "len(np.unique(cr_wid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZiXNiYVWvqR"
      },
      "source": [
        "## REDO ALL PREVIOUS ANALYSIS w/ MORE TOKENS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5sJzO88Vl-X"
      },
      "outputs": [],
      "source": [
        "freq_ids = np.intersect1d(cr_wid, freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTm0Bo-BXOMR"
      },
      "outputs": [],
      "source": [
        "freq_ids = list(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq5eU7jGW3EG"
      },
      "outputs": [],
      "source": [
        "len(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNGKpV64WphK"
      },
      "outputs": [],
      "source": [
        "# get token embedding (w/o positional embedding), assuming share_emd=True.\n",
        "it2t_token_embeddings = task_it2t.encoder.softmax.EmbLookup(\n",
        "    task_it2t.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "t2t_token_embeddings = task_t2t.encoder.softmax.EmbLookup(\n",
        "    task_t2t.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "t2t_twin_token_embeddings = task_t2t_twin.encoder.softmax.EmbLookup(\n",
        "    task_t2t_twin.theta.encoder.softmax, freq_ids)\n",
        "\n",
        "fetches = py_utils.NestedMap({\n",
        "    \"it2t_emb\": it2t_token_embeddings,\n",
        "    \"t2t_emb\": t2t_token_embeddings,\n",
        "    \"t2t_twin_emb\": t2t_twin_token_embeddings\n",
        "})\n",
        "\n",
        "print(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fSZppjcWphX"
      },
      "outputs": [],
      "source": [
        "emb_output = sess.run(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GRB_NkWWphY"
      },
      "outputs": [],
      "source": [
        "it2t_emb = emb_output[\"it2t_emb\"]\n",
        "t2t_emb = emb_output[\"t2t_emb\"]\n",
        "t2t_twin_emb = emb_output[\"t2t_twin_emb\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n8ShZPmWphZ"
      },
      "outputs": [],
      "source": [
        "def cos_similarity(vecs):\n",
        "  dotp = vecs.dot(vecs.T)\n",
        "  norm = np.sqrt((vecs ** 2).sum(1))\n",
        "  length = np.outer(norm, norm)\n",
        "  return dotp / length - np.eye(len(vecs))\n",
        "\n",
        "def k_nn(sim_matrix, k=-1):\n",
        "  return np.argsort(sim_matrix, -1)[:,::-1][:, :k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR5cJ5JpWpha"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_it2t = cos_similarity(it2t_emb)\n",
        "knn_it2t_10 = k_nn(sim_matrix_it2t, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxFgkDJZWphb"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_t2t = cos_similarity(t2t_emb)\n",
        "knn_t2t_10 = k_nn(sim_matrix_t2t, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIFe89WLWphc"
      },
      "outputs": [],
      "source": [
        "# obtain top 10 similar words\n",
        "sim_matrix_t2t_twin = cos_similarity(t2t_twin_emb)\n",
        "knn_t2t_twin_10 = k_nn(sim_matrix_t2t_twin, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgojrUyeWphd"
      },
      "outputs": [],
      "source": [
        "# obtain top 5 similar words\n",
        "knn_it2t_5 = k_nn(sim_matrix_it2t, 5)\n",
        "knn_t2t_5 = k_nn(sim_matrix_t2t, 5)\n",
        "knn_t2t_twin_5 = k_nn(sim_matrix_t2t_twin, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNN9s_ADWphe"
      },
      "outputs": [],
      "source": [
        "knn_it2t_10.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN4oGZe2Wphf"
      },
      "outputs": [],
      "source": [
        "knn_t2t_twin_10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT5rojxhWphh"
      },
      "source": [
        "### Check nearest words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8zXzhoTWphi"
      },
      "outputs": [],
      "source": [
        "def check_id(rid, freq_ids, knn):\n",
        "  print(\"query:\", input_gen._vocabulary._decode([int(freq_ids[rid])]))\n",
        "  print(\"similar words:\", [input_gen._vocabulary._decode([int(freq_ids[i])])  for i in knn[rid]])\n",
        "\n",
        "def check_word(word, freq_ids, knn):\n",
        "  wids = input_gen._vocabulary._encode(word)\n",
        "  for wid in wids:\n",
        "    # skip the empty token..\n",
        "    if wid == 3: continue\n",
        "    rid = freq_ids.index(wid)\n",
        "    check_id(rid, freq_ids, knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfGw7i3IWphn"
      },
      "source": [
        "### Quantitive comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bpcoMTJWphn"
      },
      "outputs": [],
      "source": [
        "def diff_scores(knn1, knn2, k):\n",
        "  return [len(np.intersect1d(knn1[i], knn2[i]))/k for i in range(len(knn1))] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn0e20llWpho"
      },
      "outputs": [],
      "source": [
        "top_k = 100\n",
        "it2t_vs_t2t = np.array(diff_scores(k_nn(sim_matrix_it2t, top_k), k_nn(sim_matrix_t2t, top_k), top_k))\n",
        "it2t_vs_t2t += np.array(diff_scores(k_nn(sim_matrix_it2t, top_k), k_nn(sim_matrix_t2t_twin, top_k), top_k))\n",
        "it2t_vs_t2t = it2t_vs_t2t/2\n",
        "np.mean(it2t_vs_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdLhFeA3Wpho"
      },
      "outputs": [],
      "source": [
        "t2t_vs_t2t = diff_scores(k_nn(sim_matrix_t2t, top_k), k_nn(sim_matrix_t2t_twin, top_k), top_k)\n",
        "np.mean(t2t_vs_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPBd4TdtWphp"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set_context('talk')\n",
        "\n",
        "distplot = lambda x, c, l: sns.distplot(x, kde=True,\n",
        "                            kde_kws={\"linewidth\": 3,\n",
        "                            \"alpha\": 0.8, \"color\": c, \"label\": l},\n",
        "                            hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
        "                            \"alpha\": 0.5, \"color\": c})\n",
        "\n",
        "distplot(it2t_vs_t2t, 'g', 'it2t vs t2t')\n",
        "distplot(t2t_vs_t2t, 'orange', 't2t vs t2t')\n",
        "plt.xlabel(\"top 10 nearest neighbor coherence\")\n",
        "plt.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXVdwLgC32L4"
      },
      "outputs": [],
      "source": [
        "top_ks = [1, 5, 10, 20, 50, 100, 200, 500]\n",
        "it2t_vs_t2t_k = {k:diff_scores(k_nn(sim_matrix_it2t, k), k_nn(sim_matrix_t2t, k), k) for k in top_ks}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pccifyuE4nPp"
      },
      "outputs": [],
      "source": [
        "[np.mean(it2t_vs_t2t_k[k]) for k in top_ks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ8dzF6z4TCx"
      },
      "outputs": [],
      "source": [
        "plt.plot(top_ks, [np.mean(it2t_vs_t2t_k[k]) for k in top_ks])\n",
        "plt.xlabel(\"Number of neighbors (k)\")\n",
        "plt.ylabel(\"Avg. coherence score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA16wVPkWphq"
      },
      "outputs": [],
      "source": [
        "def id2word(rid):\n",
        "  return(input_gen._vocabulary._decode([int(freq_ids[rid])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVm8vwx2Wphr"
      },
      "outputs": [],
      "source": [
        "query = 'abstract'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv7LJEFWWphs"
      },
      "outputs": [],
      "source": [
        "# most dissimilar words (t2t vs t2t)\n",
        "np.vectorize(id2word)(np.argsort(t2t_vs_t2t))[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcJiOX46Wphs"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def r2(x, y):\n",
        "    return stats.pearsonr(x, y)[0] ** 2\n",
        "\n",
        "sns.regplot(t2t_vs_t2t, it2t_vs_t2t, color='green', scatter_kws={'alpha':0.1})\n",
        "plt.xlabel(\"t2t vs t2t coherence score\")\n",
        "plt.ylabel(\"it2t vs t2t coherence score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQjSHe8PWphs"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def r2(x, y):\n",
        "    return stats.pearsonr(x, y)[0] ** 2\n",
        "\n",
        "np.sqrt(r2(it2t_vs_t2t, t2t_vs_t2t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naS3xwUjgReH"
      },
      "outputs": [],
      "source": [
        "concrete_scores[\"C\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1REPp5T8Xoc8"
      },
      "outputs": [],
      "source": [
        "conc_m = concrete_scores[\"Conc.M\"][concrete_scores[\"is_wordpiece\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnXPNPF8HtB_"
      },
      "outputs": [],
      "source": [
        "len(conc_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-_RFJEjEuy8"
      },
      "outputs": [],
      "source": [
        "len(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVTd4juUXu-H"
      },
      "outputs": [],
      "source": [
        "cr_it2t_vs_t2t = [it2t_vs_t2t[freq_ids.index(ids)] for ids in cr_wid if ids in freq_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57TSgwaaC9_4"
      },
      "outputs": [],
      "source": [
        "conc_m = conc_m[[(w in freq_ids) for w in cr_wid]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkdRLDjB8szh"
      },
      "outputs": [],
      "source": [
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.data.path.append('/usr/local/google/home/runzheyang/nltk_data')\n",
        "get_pos = lambda x: nltk.pos_tag(nltk.word_tokenize(input_gen._vocabulary.decode([int(x)])))[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Tb-hIIFFy5"
      },
      "outputs": [],
      "source": [
        "POS = [get_pos(ids) for ids in cr_wid if ids in freq_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DfBbvMpFF1u"
      },
      "outputs": [],
      "source": [
        "np.unique(POS, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OldHaj1AFF56"
      },
      "outputs": [],
      "source": [
        "sns.histplot(POS)\n",
        "plt.xticks(rotation=70)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTRzZ1lfLZav"
      },
      "outputs": [],
      "source": [
        "cr_it2t_vs_t2t = np.array(cr_it2t_vs_t2t)\n",
        "conc_m = np.array(conc_m)\n",
        "POS = np.array(POS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP9Gosaec96y"
      },
      "outputs": [],
      "source": [
        "is_in = lambda x, y: [x_ in y for x_ in x] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKwycmPbYSjP"
      },
      "outputs": [],
      "source": [
        "sns.regplot(conc_m, cr_it2t_vs_t2t, scatter_kws={'alpha':0.1})\n",
        "pos_set = ['VB', 'VBD', 'VBG', 'VBN']\n",
        "sns.regplot(conc_m[is_in(POS, pos_set)], cr_it2t_vs_t2t[is_in(POS, pos_set)], color='red', scatter_kws={'alpha':0.1})\n",
        "plt.ylabel(\"it2t vs t2t coherence score\")\n",
        "plt.xlabel(\"concreteness\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldKg3Snoda2F"
      },
      "outputs": [],
      "source": [
        "sns.regplot(conc_m, cr_it2t_vs_t2t, scatter_kws={'alpha':0.1})\n",
        "pos_set = ['NN', 'NNS']\n",
        "sns.regplot(conc_m[is_in(POS, pos_set)], cr_it2t_vs_t2t[is_in(POS, pos_set)], color='orange', scatter_kws={'alpha':0.1})\n",
        "plt.ylabel(\"it2t vs t2t coherence score\")\n",
        "plt.xlabel(\"concreteness\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59EDqxCEeQ4J"
      },
      "outputs": [],
      "source": [
        "sns.regplot(conc_m, cr_it2t_vs_t2t, scatter_kws={'alpha':0.1})\n",
        "pos_set = ['JJ', 'JJR', 'JJS']\n",
        "sns.regplot(conc_m[is_in(POS, pos_set)], cr_it2t_vs_t2t[is_in(POS, pos_set)], color='pink', scatter_kws={'alpha':0.1})\n",
        "plt.ylabel(\"it2t vs t2t coherence score\")\n",
        "plt.xlabel(\"concreteness\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3xynX0xL6dF"
      },
      "outputs": [],
      "source": [
        "sns.regplot(conc_m, cr_it2t_vs_t2t, scatter_kws={'alpha':0.1})\n",
        "plt.ylabel(\"it2t vs t2t coherence score\")\n",
        "plt.xlabel(\"concreteness\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKEIEpWjLxLS"
      },
      "outputs": [],
      "source": [
        "r2(cr_it2t_vs_t2t[POS=='NN'], conc_m[POS=='NN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp8B-G3rL-Ro"
      },
      "outputs": [],
      "source": [
        "r2(cr_it2t_vs_t2t, conc_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy-v9EhdY6It"
      },
      "outputs": [],
      "source": [
        "check_up_right = lambda x, y: [input_gen._vocabulary.decode([int(ids)]) for ids in np.array(freq_ids)[(np.array(cr_it2t_vs_t2t) \u003e x) \u0026 (np.array(conc_m) \u003e y)]]\n",
        "check_up_left = lambda x, y: [input_gen._vocabulary.decode([int(ids)]) for ids in np.array(freq_ids)[(np.array(cr_it2t_vs_t2t) \u003c x) \u0026 (np.array(conc_m) \u003e y)]]\n",
        "check_bt_right = lambda x, y: [input_gen._vocabulary.decode([int(ids)]) for ids in np.array(freq_ids)[(np.array(cr_it2t_vs_t2t) \u003e x) \u0026 (np.array(conc_m) \u003c y)]]\n",
        "check_bt_left = lambda x, y: [input_gen._vocabulary.decode([int(ids)]) for ids in np.array(freq_ids)[(np.array(cr_it2t_vs_t2t) \u003c x) \u0026 (np.array(conc_m) \u003c y)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXCnVbJ4RBX-"
      },
      "outputs": [],
      "source": [
        "len(cr_wid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-2myOJxRvQj"
      },
      "outputs": [],
      "source": [
        "len(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECBAavCBZiCM"
      },
      "outputs": [],
      "source": [
        "np.array(check_up_right(0.65, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUCjlasycvlS"
      },
      "outputs": [],
      "source": [
        "np.array(check_up_left(0.25, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bel84vCHeE85"
      },
      "outputs": [],
      "source": [
        "np.array(check_bt_right(0.5, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXD42MiHeX6K"
      },
      "outputs": [],
      "source": [
        "np.array(check_bt_left(0.2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-wX4DRIyZpX"
      },
      "outputs": [],
      "source": [
        "query = 'sodium'\n",
        "check_word(query, freq_ids, knn_it2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_10)\n",
        "check_word(query, freq_ids, knn_t2t_twin_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JDNHttpede0"
      },
      "outputs": [],
      "source": [
        "from google3.learning.brain.research.babelfish.multimodal import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBhxVa8uvdDa"
      },
      "outputs": [],
      "source": [
        "datasets.open_image_text_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ubpHSAv0h-a"
      },
      "outputs": [],
      "source": [
        "1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93ODNPUeh7y6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Embedding inspection (local).ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "18YlgoYEycxsLfO-Q7i2gAkmWYXCsKHLa",
          "timestamp": 1630076923270
        },
        {
          "file_id": "1LgQaLkIgTAMix0PrNiBc8DnHk66U324g",
          "timestamp": 1624467180657
        },
        {
          "file_id": "1DWQpm9DyYFhZTUL28PSCtUIugu7pZTTD",
          "timestamp": 1623879707760
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
