{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcYJIEwd3As"
      },
      "source": [
        "#### local run command\n",
        "`blaze run -c opt learning/brain/research/babelfish/colab:colab_notebook --define=babelfish_task=multimodal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7ZcyyqZKJi"
      },
      "outputs": [],
      "source": [
        "import lingvo.compat as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from lingvo.core import py_utils\n",
        "from google3.learning.brain.research.babelfish import tokenizers\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_baselines as it_params\n",
        "\n",
        "# from google3.pyglib import gfiler\n",
        "\n",
        "from google3.perftools.accelerators.xprof.api.colab import xprof\n",
        "\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZujlTGZZlK"
      },
      "outputs": [],
      "source": [
        "mdl_it2t = it_params.ImageText2TextLMSmall()\n",
        "mdl_t2t = it_params.Text2TextLMSmall()\n",
        "\n",
        "p_it2t = mdl_it2t.Task()\n",
        "p_t2t = mdl_t2t.Task()\n",
        "\n",
        "# Note: We use the name as part of var/name scopes, you need to ensure that\n",
        "# the name here matches for checkpoints to load successfully.\n",
        "\n",
        "p_it2t.name = 'ImageText2TextLMTask'\n",
        "p_t2t.name = 'Text2TextLM'\n",
        "p_it2t.input = mdl_it2t.Train()\n",
        "p_t2t.input = mdl_t2t.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CafizIxXQfa"
      },
      "outputs": [],
      "source": [
        "# We are going to use the global graph for this entire colab.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the Task.\n",
        "task_it2t = p_it2t.Instantiate()\n",
        "task_t2t = p_t2t.Instantiate()\n",
        "\n",
        "# Create variables by running FProp.\n",
        "_ = task_it2t.FPropDefaultTheta()\n",
        "_ = task_t2t.FPropDefaultTheta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcdhCnAGprFr"
      },
      "outputs": [],
      "source": [
        "# Create a new session and initialize all the variables.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCpH22KqYgVQ"
      },
      "outputs": [],
      "source": [
        "# Setup the checkpoint loading rules for OverrideVarsFromCheckpoints.\n",
        "loading_rules = [\n",
        "    (\n",
        "        \"(.*)\",  # Regexp match all variables in the ckpt.\n",
        "        \"%s\"     # Format string to use the saved var name as is.\n",
        "    )\n",
        "]\n",
        "loading_rules_twin = [\n",
        "    (\n",
        "        \"Text2TextLM_Twin/(.*/var:0$)\",  \n",
        "        \"Text2TextLM/%s\"    \n",
        "    )\n",
        "]\n",
        "\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "\n",
        "ckpts_loading_rules = lambda x, y:{\n",
        "    x: (y, ignore_rules)\n",
        "}\n",
        "\n",
        "ckpt_path_it2t = '/cns/jn-d/home/ziruiw/brain/rs=6.3/ImageText2TextLM.small.ibz4096.tbz512.PrefixLM.Res50.Trans2.BatchMajor.RelPos.LR5e4.WD1e2/train/ckpt-01000000'\n",
        "ckpt_path_t2t = '/cns/tp-d/home/runzheyang/brain/rs=6.3/text2textlm.small.fixedtranspose.1/train/ckpt-01000000'\n",
        "\n",
        "# Load the saved checkpoint into the session.\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_it2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_it2t, loading_rules))(sess)\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_t2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_t2t, loading_rules))(sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHb3afGKaE3J"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xmQJyqDPwhm"
      },
      "outputs": [],
      "source": [
        "import t5\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "mdl_it2t.TRAIN_BATCH_SIZE = 64\n",
        "mdl_it2t.EVAL_BATCH_SIZE = 64\n",
        "mdl_t2t.TRAIN_BATCH_SIZE = 64\n",
        "mdl_t2t.EVAL_BATCH_SIZE = 64\n",
        "input_p = mdl_t2t.Test()\n",
        "\n",
        "input_gen = input_p.Instantiate()\n",
        "input_gen.Initialize(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhIMLxSbo0A"
      },
      "outputs": [],
      "source": [
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_finetune as gen_params\n",
        "mdl_cnn = gen_params.FinetuneCNNDMSmall()\n",
        "p_cnn = mdl_cnn.Task()\n",
        "p_cnn.input = mdl_cnn.Train()\n",
        "task_cnn = p_cnn.Instantiate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oKaKL-HaQWY"
      },
      "outputs": [],
      "source": [
        "input_batch = input_gen.GetPreprocessedInputBatch()\n",
        "encoder_inputs = input_batch.encoder_inputs\n",
        "encoder_paddings = input_batch.encoder_paddings\n",
        "\n",
        "# encoder\n",
        "sources = py_utils.NestedMap(ids=encoder_inputs, paddings=encoder_paddings)\n",
        "def BeamsearchDec(task, sources):\n",
        "  encoder_embeddings = task.encoder.FPropEmbeddings(task.theta.encoder, sources)\n",
        "  encoder_outputs = task.encoder.FPropTransformerLayers(\n",
        "      task.theta.encoder, encoder_embeddings)\n",
        "  encoder_outputs = task.decoder.AddExtraDecodingInfo(encoder_outputs,\n",
        "                                                      input_batch)\n",
        "  decoded = task.decoder.BeamSearchDecode(encoder_outputs)\n",
        "\n",
        "  decode_outs = py_utils.NestedMap()\n",
        "  ids = input_batch.decoder_inputs\n",
        "  batch_size = py_utils.GetShape(ids)[0]\n",
        "\n",
        "  with tf.name_scope('spm_hyp'):\n",
        "    # print(task.input_generator.__dict__)\n",
        "    topk_decoded = task_cnn.input_generator.tokenizer.IdsToStrings(\n",
        "        decoded.topk_ids)\n",
        "    topk_decoded = tf.reshape(topk_decoded, [batch_size, -1])\n",
        "\n",
        "  decode_outs.topk_decoded = tf.identity(topk_decoded, name='topk_decoded')\n",
        "  if 'weight' in input_batch:\n",
        "    decode_outs.weight = input_batch.weight\n",
        "  else:\n",
        "    decode_outs.weight = tf.ones([batch_size])\n",
        "\n",
        "  return decode_outs\n",
        "\n",
        "decode_outs = py_utils.NestedMap({\n",
        "    \"input\": encoder_inputs,\n",
        "    \"it2t\": BeamsearchDec(task_it2t, sources),\n",
        "    \"t2t\": BeamsearchDec(task_t2t, sources)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT3MbibuPpRW"
      },
      "outputs": [],
      "source": [
        "input_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fof_eE3WaoDb"
      },
      "outputs": [],
      "source": [
        "decode_outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92zH6hbCaZ4R"
      },
      "outputs": [],
      "source": [
        "test_out = sess.run(decode_outs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-HxOScMf3JY"
      },
      "outputs": [],
      "source": [
        "id = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PveVpAo2OJK9"
      },
      "outputs": [],
      "source": [
        "input_gen._vocabulary.decode([int(w) for w in test_out[\"input\"][id]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8dwAYi2flbP"
      },
      "outputs": [],
      "source": [
        "test_out['it2t']['topk_decoded'][id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-DQwUcig9Pg"
      },
      "outputs": [],
      "source": [
        "test_out['t2t']['topk_decoded'][id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rADZlVaIhOZv"
      },
      "outputs": [],
      "source": [
        "np.mean([len(test_out['it2t']['topk_decoded'][id][0]) for id in range(64)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jURejqBZtp26"
      },
      "outputs": [],
      "source": [
        "np.mean([len(test_out['t2t']['topk_decoded'][id][0]) for id in range(64)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhfD7T5eDlSz"
      },
      "outputs": [],
      "source": [
        "from google3.pyglib import gfile\n",
        "import pandas as pd\n",
        "\n",
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/concreteness.xlsx', 'rb') as fh:  \n",
        "  concrete_scores = pd.read_excel(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrzvytHSEYW9"
      },
      "outputs": [],
      "source": [
        "concrete_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xoIeVREFQQ6"
      },
      "outputs": [],
      "source": [
        "bool_wordpiece = []\n",
        "for i, w in enumerate(list(concrete_scores[\"Word\"])):\n",
        "  ids = input_gen._vocabulary.encode(str(w))\n",
        "  bool_wordpiece.append(len(ids) == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7g1tYWtIL4z"
      },
      "outputs": [],
      "source": [
        "concrete_scores['is_wordpiece'] = bool_wordpiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqy-AqqGR2uQ"
      },
      "outputs": [],
      "source": [
        "concrete_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF25ZFb--_ZB"
      },
      "outputs": [],
      "source": [
        "concrete_scores[\"Conc.M\"][concrete_scores[\"is_wordpiece\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO_VPygeUgY7"
      },
      "outputs": [],
      "source": [
        "cr_wid = [input_gen._vocabulary.encode(w)[0] for w in concrete_scores[\"Word\"][concrete_scores[\"is_wordpiece\"]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIYGTd6uftMh"
      },
      "outputs": [],
      "source": [
        "cr_wid = np.array(cr_wid).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5n7KejXCSpv"
      },
      "outputs": [],
      "source": [
        "cr_score = np.array(concrete_scores[\"Conc.M\"][concrete_scores[\"is_wordpiece\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d8g3LTrCXut"
      },
      "outputs": [],
      "source": [
        "cr_dict = dict(zip(cr_wid, cr_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyUNsRubgsSu"
      },
      "outputs": [],
      "source": [
        "it2t_gen_words = [input_gen._vocabulary.encode(s) for s in test_out['it2t']['topk_decoded'].flatten()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAay5_nd8S7X"
      },
      "outputs": [],
      "source": [
        "cscore_it2t = [[cr_dict[w] for w in s if w in cr_wid] for s in it2t_gen_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YGLLr1b8w7G"
      },
      "outputs": [],
      "source": [
        "t2t_gen_words = [input_gen._vocabulary.encode(s) for s in test_out['t2t']['topk_decoded'].flatten()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud20TJnuC4me"
      },
      "outputs": [],
      "source": [
        "cscore_t2t = [[cr_dict[w] for w in s if w in cr_wid] for s in t2t_gen_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wtP-EY2C6pL"
      },
      "outputs": [],
      "source": [
        "def lflatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujBvWxMQC7xu"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rk4adI7DSa6"
      },
      "outputs": [],
      "source": [
        "sns.distplot(lflatten(cscore_it2t), color='orange', label='it2t')\n",
        "sns.distplot(lflatten(cscore_t2t), color='green', label='t2t')\n",
        "\n",
        "plt.xlabel(\"Concreteness\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTlRnSffEdQ2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Generation inspection.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1h8G1MRvWWWiVv1qG-KIwkZA8xB4DvOtB",
          "timestamp": 1630076994257
        },
        {
          "file_id": "1DR8HjIsy6Xt-vnSBEsvL5ffseT0UczHu",
          "timestamp": 1628620787771
        },
        {
          "file_id": "18YlgoYEycxsLfO-Q7i2gAkmWYXCsKHLa",
          "timestamp": 1626109854299
        },
        {
          "file_id": "1LgQaLkIgTAMix0PrNiBc8DnHk66U324g",
          "timestamp": 1624467180657
        },
        {
          "file_id": "1DWQpm9DyYFhZTUL28PSCtUIugu7pZTTD",
          "timestamp": 1623879707760
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
