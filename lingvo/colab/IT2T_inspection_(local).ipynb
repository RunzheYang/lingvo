{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcYJIEwd3As"
      },
      "source": [
        "#### local run command\n",
        "`blaze run -c opt learning/brain/research/babelfish/colab:colab_notebook --define=babelfish_task=multimodal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7ZcyyqZKJi"
      },
      "outputs": [],
      "source": [
        "import lingvo.compat as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import os\n",
        "\n",
        "from lingvo.core import py_utils\n",
        "from google3.learning.brain.research.babelfish import tokenizers\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_baselines as it_params\n",
        "\n",
        "# from google3.pyglib import gfiler\n",
        "\n",
        "from google3.perftools.accelerators.xprof.api.colab import xprof\n",
        "\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZujlTGZZlK"
      },
      "outputs": [],
      "source": [
        "# mdl = it_params.ImageText2TextLMSmall()\n",
        "mdl = it_params.Text2TextLMSmall()\n",
        "p = mdl.Task()\n",
        "\n",
        "# Note: We use the name as part of var/name scopes, you need to ensure that\n",
        "# the name here matches for checkpoints to load successfully.\n",
        "\n",
        "# p.name = 'ImageText2TextLMTask'\n",
        "p.name = 'Text2TextLM'\n",
        "p.input = mdl.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CafizIxXQfa"
      },
      "outputs": [],
      "source": [
        "# We are going to use the global graph for this entire colab.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the Task.\n",
        "task = p.Instantiate()\n",
        "\n",
        "# Create variables by running FProp.\n",
        "_ = task.FPropDefaultTheta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcdhCnAGprFr"
      },
      "outputs": [],
      "source": [
        "# Create a new session and initialize all the variables.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mAMVdCJgUp9"
      },
      "outputs": [],
      "source": [
        "# Setup the checkpoint loading rules for OverrideVarsFromCheckpoints.\n",
        "loading_rules = [\n",
        "    (\n",
        "        \"(.*)\",  # Regexp match all variables in the ckpt.\n",
        "        \"%s\"     # Format string to use the saved var name as is.\n",
        "    )\n",
        "]\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "# ckpt_path = '/cns/jn-d/home/ziruiw/brain/rs=6.3/ImageText2TextLM.small.ibz4096.tbz512.PrefixLM.Res50.Trans2.BatchMajor.RelPos.LR5e4.WD1e2/train/ckpt-01000000'\n",
        "# ckpt_path = '/cns/tp-d/home/runzheyang/brain/rs=6.3/text2textlm.small/train/ckpt-01000000'\n",
        "\n",
        "ckpts_loading_rules = {\n",
        "    ckpt_path: (loading_rules, ignore_rules)\n",
        "}\n",
        "\n",
        "# Load the saved checkpoint into the session.\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(), ckpts_loading_rules)(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2dxcp9hG3m2"
      },
      "outputs": [],
      "source": [
        "# feeds = {\n",
        "#     'text': tf.placeholder(tf.string, shape=[1,])\n",
        "# }\n",
        "# input_batch = py_utils.NestedMap(encoder_inputs=feeds['text'], decoder_inputs=feeds['text'])\n",
        "\n",
        "# mdl.T2T_BATCH_SIZE = 1\n",
        "# mdl.I2T_BATCH_SIZE = 1\n",
        "\n",
        "mdl.BATCH_SIZE = 1\n",
        "input_p = mdl.Train()\n",
        "\n",
        "input_gen = input_p.Instantiate()\n",
        "input_batch = input_gen.GetPreprocessedInputBatch()\n",
        "\n",
        "encoder_inputs = input_batch.encoder_inputs\n",
        "decoder_inputs = input_batch.decoder_inputs\n",
        "encoder_paddings = input_batch.encoder_paddings\n",
        "decoder_paddings = input_batch.decoder_paddings\n",
        "\n",
        "# encoder\n",
        "sources = py_utils.NestedMap(\n",
        "    ids=encoder_inputs, paddings=encoder_paddings)\n",
        "encoder_embeddings = task.encoder.FPropEmbeddings(task.theta.encoder, sources)\n",
        "encoder_outputs = task.encoder.FPropTransformerLayers(\n",
        "    task.theta.encoder, encoder_embeddings)\n",
        "\n",
        "# decoder\n",
        "targets = py_utils.NestedMap(\n",
        "    ids=decoder_inputs, paddings=decoder_paddings)\n",
        "predictions = task.decoder.ComputePredictions(task.theta.decoder, encoder_outputs, targets)\n",
        "\n",
        "# Notice that we are calling this with task.theta which ensures that we are\n",
        "# using the same variables which we have just loaded.\n",
        "fetches = py_utils.NestedMap(\n",
        "          {\"encoder_inputs\": encoder_inputs,\n",
        "           \"sources\": sources,\n",
        "           \"encoder_embeddings\": encoder_embeddings,\n",
        "           \"encoder_outputs\": encoder_outputs,\n",
        "           \"decoder_inputs\": decoder_inputs,\n",
        "           \"targets\": targets,\n",
        "           \"predictions\":predictions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaZ6Wek_7WZN"
      },
      "outputs": [],
      "source": [
        "fetches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpLY7b2Z-km0"
      },
      "outputs": [],
      "source": [
        "test_output = sess.run(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZL4hirx_eil"
      },
      "outputs": [],
      "source": [
        "test_output[\"encoder_embeddings\"][\"input_embs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR7w_4h5IUcS"
      },
      "outputs": [],
      "source": [
        "test_output[\"encoder_embeddings\"][\"input_embs\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsGOoa80XFT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "IT2T inspection (local).ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1a07n5r3GDqVqgcvB36t8FTfPL9H9LuuX",
          "timestamp": 1630077369023
        },
        {
          "file_id": "1LgQaLkIgTAMix0PrNiBc8DnHk66U324g",
          "timestamp": 1624467180657
        },
        {
          "file_id": "1DWQpm9DyYFhZTUL28PSCtUIugu7pZTTD",
          "timestamp": 1623879707760
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
