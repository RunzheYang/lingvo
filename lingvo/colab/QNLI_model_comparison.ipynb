{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcYJIEwd3As"
      },
      "source": [
        "#### local run command\n",
        "`blaze run -c opt learning/brain/research/babelfish/colab:colab_notebook --define=babelfish_task=multimodal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7ZcyyqZKJi"
      },
      "outputs": [],
      "source": [
        "import lingvo.compat as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import os\n",
        "\n",
        "from lingvo.core import py_utils\n",
        "from google3.learning.brain.research.babelfish import tokenizers\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_baselines as it_params\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import nlu_baselines as nlu_params\n",
        "\n",
        "# from google3.pyglib import gfiler\n",
        "\n",
        "from google3.perftools.accelerators.xprof.api.colab import xprof\n",
        "\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdjX2415o8j_"
      },
      "source": [
        "## Load IT2T and T2T models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZujlTGZZlK"
      },
      "outputs": [],
      "source": [
        "mdl_it2t = nlu_params.QNLIClassification()\n",
        "mdl_t2t = nlu_params.QNLIClassification()\n",
        "\n",
        "mdl_it2t.DROPOUT_RATE = 0.0\n",
        "mdl_t2t.DROPOUT_RATE = 0.0\n",
        "\n",
        "p_it2t = mdl_it2t.Task()\n",
        "p_t2t = mdl_t2t.Task()\n",
        "\n",
        "# Note: We use the name as part of var/name scopes, you need to ensure that\n",
        "# the name here matches for checkpoints to load successfully.\n",
        "\n",
        "p_it2t.name = 'GLUETask_IT2T'\n",
        "p_t2t.name = 'GLUETask_T2T'\n",
        "\n",
        "# imagetext2text:\n",
        "p_it2t.decoder.shared_emb.softmax.use_num_classes_major_weight = True\n",
        "p_it2t.encoder.shared_emb.softmax.use_num_classes_major_weight = True\n",
        "\n",
        "# text2text:\n",
        "p_t2t.decoder.shared_emb.softmax.use_num_classes_major_weight = False\n",
        "p_t2t.encoder.shared_emb.softmax.use_num_classes_major_weight = False\n",
        "\n",
        "p_it2t.input = mdl_it2t.Train()\n",
        "p_t2t.input = mdl_t2t.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CafizIxXQfa"
      },
      "outputs": [],
      "source": [
        "# We are going to use the global graph for this entire colab.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the Task.\n",
        "task_it2t = p_it2t.Instantiate()\n",
        "task_t2t = p_t2t.Instantiate()\n",
        "\n",
        "# Create variables by running FProp.\n",
        "_ = task_it2t.FPropDefaultTheta()\n",
        "_ = task_t2t.FPropDefaultTheta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcdhCnAGprFr"
      },
      "outputs": [],
      "source": [
        "# Create a new session and initialize all the variables.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mAMVdCJgUp9"
      },
      "outputs": [],
      "source": [
        "# Setup the checkpoint loading rules for OverrideVarsFromCheckpoints.\n",
        "loading_rules_it2t = [\n",
        "    (\n",
        "        \"GLUETask_IT2T/(.*/var:0$)\",  \n",
        "        \"GLUETask/%s\"    \n",
        "    )\n",
        "]\n",
        "\n",
        "loading_rules_t2t = [\n",
        "    (\n",
        "        \"GLUETask_T2T/(.*/var:0$)\",  \n",
        "        \"GLUETask/%s\"    \n",
        "    )\n",
        "]\n",
        "\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "\n",
        "ckpts_loading_rules = lambda x, y:{\n",
        "    x: (y, ignore_rules)\n",
        "}\n",
        "\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "ckpt_path_it2t = '/cns/tp-d/home/runzheyang/brain/rs=6.3/qnli.imagetext2textlm.small.fixedtranspose.1m.lr3e-5.lineardecay.dropout01/train/ckpt-00010000'\n",
        "ckpt_path_t2t = '/cns/tp-d/home/runzheyang/brain/rs=6.3/qnli.text2textlm.small.fixedtranspose.1m.lr3e-5.lineardecay.dropout01/train/ckpt-00010000'\n",
        "\n",
        "# Load the saved checkpoint into the session.\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_it2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_it2t, loading_rules_it2t))(sess)\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(p_t2t.name+\"//*\"), ckpts_loading_rules(ckpt_path_t2t, loading_rules_t2t))(sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruvP0NsdpDVj"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yuj1zLXYvbH"
      },
      "outputs": [],
      "source": [
        "import t5\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# total 5463\n",
        "mdl_t2t.TRAIN_BATCH_SIZE = 1\n",
        "mdl_t2t.EVAL_BATCH_SIZE = 1\n",
        "input_p = mdl_t2t.Test()\n",
        "\n",
        "input_gen = input_p.Instantiate()\n",
        "input_gen.Initialize(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoFU1GAu2cE8"
      },
      "outputs": [],
      "source": [
        "#@title Sample Tasks/Mixtures examples\n",
        "task_name = 'glue_qnli_v002' #@param\n",
        "split = 'validation' #@param\n",
        "inputs_length = 256  #@param\n",
        "targets_length = 32  #@param\n",
        "num_samples =      5#@param\n",
        "\n",
        "task = t5.data.TaskRegistry.get(task_name)\n",
        "for s in task.splits:\n",
        "    print('%s: %d' % (s, task.num_input_examples(s)))\n",
        "print()\n",
        "\n",
        "ds = task.get_dataset(split=split, sequence_length={\"inputs\": inputs_length, \"targets\": targets_length})\n",
        "print(\"A few preprocessed {} examples...\".format(split))\n",
        "\n",
        "def print_example(example):\n",
        "  print('===')\n",
        "  print('input:')\n",
        "  print(input_gen._vocabulary._decode(\n",
        "        [int(ids) for ids in example['inputs']]))\n",
        "  print('output:')\n",
        "  print(example['targets_pretokenized'])\n",
        "\n",
        "for ex in tfds.as_numpy(ds.take(num_samples)):\n",
        "  print_example(ex)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gezwJ1zMp_T2"
      },
      "outputs": [],
      "source": [
        "def process_ex(ex):\n",
        "  ids = np.pad(ex['inputs'], (1, 511-len(ex['inputs'])), 'constant', \n",
        "               constant_values=(0, 0)).reshape(1,-1)\n",
        "  paddings = np.pad(np.zeros(len(ex['inputs'])+1), (0, 511-len(ex['inputs'])), \n",
        "                    'constant', constant_values=(1, 1)).reshape(1,-1)\n",
        "  labels = 1 if ex['targets_pretokenized'] == b'entailment' else 0\n",
        "  return ids, paddings, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNAzVx5xQ6N"
      },
      "source": [
        "## Evaluation on the whole validation test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXsOU42BpYs6"
      },
      "outputs": [],
      "source": [
        "def get_predictions(task, sources):\n",
        "  # encoder\n",
        "  encoder_embeddings = task.encoder.FPropEmbeddings(task.theta.encoder, sources)\n",
        "  encoder_outputs = task.encoder.FPropTransformerLayers(task.theta.encoder, \n",
        "                                                        encoder_embeddings)\n",
        "\n",
        "  # decoder\n",
        "  targets = py_utils.NestedMap(ids=sources.ids, paddings=sources.paddings)\n",
        "  decoder_outputs = task.decoder.ComputePredictions(task.theta.decoder,\n",
        "                                                    encoder_outputs, targets)\n",
        "\n",
        "  classifier_input = task._extract_classifier_input(sources.paddings, decoder_outputs)\n",
        "\n",
        "  predictions = task._apply_classifier(task.theta, classifier_input)\n",
        "\n",
        "  return predictions\n",
        "\n",
        "feed_ids =  tf.placeholder(tf.int32, shape=[1,512])\n",
        "feed_paddings = tf.placeholder(tf.float32, shape=[1,512])\n",
        "\n",
        "sources = py_utils.NestedMap(ids=feed_ids, paddings=feed_paddings)\n",
        "predictions_it2t = get_predictions(task_it2t, sources)\n",
        "predictions_t2t = get_predictions(task_t2t, sources)\n",
        "\n",
        "\n",
        "# Notice that we are calling this with task.theta which ensures that we are\n",
        "# using the same variables which we have just loaded.\n",
        "fetches = py_utils.NestedMap(\n",
        "          {\"sources\": sources,\n",
        "           \"predictions_it2t\":predictions_it2t,\n",
        "           \"predictions_t2t\":predictions_t2t\n",
        "           })\n",
        "\n",
        "print(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4iW6pU9_6cJ"
      },
      "outputs": [],
      "source": [
        "max([len(ex['inputs']) for ex in tfds.as_numpy(ds.take(task.num_input_examples(\"validation\")))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVARyHUt81BI"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "test_outputs = []\n",
        "\n",
        "for ex in tfds.as_numpy(ds.take(task.num_input_examples(\"validation\"))):\n",
        "  ids, paddings, label = process_ex(ex) \n",
        "  labels.append(label)\n",
        "  test_outputs.append(sess.run(fetches, {feed_ids: ids, feed_paddings: paddings}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBSHMdJBM7kO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2DvoaurYvbX"
      },
      "outputs": [],
      "source": [
        "VAL_SIZE = task.num_input_examples(\"validation\")\n",
        "print((np.array([labels[i] - np.argmax(test_outputs[i]['predictions_it2t'][\"probs\"]) for i in range(VAL_SIZE)]) == 0).sum() / VAL_SIZE)\n",
        "print((np.array([labels[i] - np.argmax(test_outputs[i]['predictions_t2t'][\"probs\"]) for i in range(VAL_SIZE)]) == 0).sum() / VAL_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KSu8S28Yvba"
      },
      "outputs": [],
      "source": [
        "def pretty_print_examples(input_str, label, prediction_it2t, prediction_t2t):\n",
        "  print(input_str)\n",
        "  print(\"label: \" + (\"\\x1b[32mPOSITIVE\\x1b[0m\" if label == 1 else \"\\x1b[31mNEGATIVE\\x1b[0m\"))\n",
        "  print(\"IT2T prediction: \" + (\"\\x1b[32mPOSITIVE\\x1b[0m\" if prediction_it2t == 1 else \"\\x1b[31mNEGATIVE\\x1b[0m\"))\n",
        "  print(\"T2T prediction: \" + (\"\\x1b[32mPOSITIVE\\x1b[0m\" if prediction_t2t == 1 else \"\\x1b[31mNEGATIVE\\x1b[0m\"))\n",
        "  print()\n",
        "\n",
        "# check a few examples from test set\n",
        "for i in range(100):\n",
        "  pred_it2t = np.argmax(test_outputs[i][\"predictions_it2t\"][\"probs\"], axis=1)\n",
        "  pred_t2t = np.argmax(test_outputs[i][\"predictions_t2t\"][\"probs\"], axis=1)\n",
        "  if pred_it2t != pred_t2t:\n",
        "    pretty_print_examples(input_gen._vocabulary._decode(\n",
        "        [int(ids) for ids in test_outputs[i][\"sources\"][\"ids\"][0]]),\n",
        "        labels[i],\n",
        "        pred_it2t,\n",
        "        pred_t2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcfA_PO8N3N0"
      },
      "outputs": [],
      "source": [
        "all_ex = [input_gen._vocabulary._decode(\n",
        "          [int(ids) for ids in test_outputs[i][\"sources\"][\"ids\"][0]]) for i in range(5463)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjDmKt_rOuvA"
      },
      "outputs": [],
      "source": [
        "it2t_ex, t2t_ex = [], []\n",
        "for i in range(5463):\n",
        "  pred_it2t = np.argmax(test_outputs[i][\"predictions_it2t\"][\"probs\"], axis=1)\n",
        "  pred_t2t = np.argmax(test_outputs[i][\"predictions_t2t\"][\"probs\"], axis=1)\n",
        "  ex = input_gen._vocabulary._decode(\n",
        "          [int(ids) for ids in test_outputs[i][\"sources\"][\"ids\"][0]])\n",
        "  if pred_it2t != labels[i]:\n",
        "    it2t_ex.append(ex)\n",
        "  if pred_t2t != labels[i]:\n",
        "    t2t_ex.append(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNYtJwxIFKHB"
      },
      "outputs": [],
      "source": [
        "len(np.intersect1d(all_ex, it2t_ex))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27rdYvDMFu9L"
      },
      "outputs": [],
      "source": [
        "len(it2t_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPus983CFXCh"
      },
      "outputs": [],
      "source": [
        "all_ex.index(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBMIbR2mGUwf"
      },
      "outputs": [],
      "source": [
        "test_outputs[1429][\"predictions_it2t\"][\"probs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqIcLeO3GetL"
      },
      "outputs": [],
      "source": [
        "test_outputs[1429][\"predictions_t2t\"][\"probs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KajivQ8yD0Ri"
      },
      "outputs": [],
      "source": [
        "query = 'qnli question: What branch is independant of the other branches? sentence: The Judiciary is independent of the executive and the legislature.'\n",
        "print(query in it2t_ex)\n",
        "print(query in t2t_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqw3KFNPPbwN"
      },
      "outputs": [],
      "source": [
        "len(np.intersect1d(it2t_ex, t2t_ex))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTCjK_f9SUNa"
      },
      "outputs": [],
      "source": [
        "len(it2t_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAPGWvZYSYLr"
      },
      "outputs": [],
      "source": [
        "len(t2t_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZZ1jTNzZQma"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from google3.pyglib import gfile\n",
        "\n",
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/qnli_validaiton', 'wt') as fh:  \n",
        "  json.dump(all_ex, fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vezbRXCBRjdr"
      },
      "outputs": [],
      "source": [
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/qnli_it2t_failue', 'wt') as fh:  \n",
        "  json.dump(it2t_ex, fh)\n",
        "\n",
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/qnli_t2t_failue', 'wt') as fh:  \n",
        "  json.dump(t2t_ex, fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmhu8_pQSZj5"
      },
      "outputs": [],
      "source": [
        "# with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/sst2_validaiton', 'r') as fh:  \n",
        "#   all_ex_ = json.load(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPhfgeU3Swde"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpVjYew3u1RU"
      },
      "outputs": [],
      "source": [
        "with gfile.Open('/cns/tp-d/home/runzheyang/brain/rs=6.3/data/5000-words.txt', 'r') as f:\n",
        "  freq_words = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn9_kRol2Pct"
      },
      "outputs": [],
      "source": [
        "input_p = mdl_t2t.Train()\n",
        "input_gen = input_p.Instantiate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "divXII6i8kA5"
      },
      "outputs": [],
      "source": [
        "freq_ids = input_gen._vocabulary._encode(freq_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaSZWPEeG5cl"
      },
      "outputs": [],
      "source": [
        "freq_ids = np.unique(freq_ids)\n",
        "freq_ids = [int(i) for i in freq_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4zdWIqaCgup"
      },
      "outputs": [],
      "source": [
        "input_gen._vocabulary._decode(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJzqXdtEC0NE"
      },
      "outputs": [],
      "source": [
        "len(freq_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QSR3czmSzHe"
      },
      "outputs": [],
      "source": [
        "it2t_fm_ids = [input_gen._vocabulary._encode(ex) for ex in it2t_ex]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1uPL2pLXx-b"
      },
      "outputs": [],
      "source": [
        "[np.intersect1d(freq_ids, ids) for ids in  it2t_fm_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q7mCbnFYBe8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "QNLI model comparison.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1veBgVWy68o4Al34EAbuebossnQkqx3jS",
          "timestamp": 1630077342530
        },
        {
          "file_id": "1crYPaHYTDMXrBcQ4K6yQQqjIBQ_buIzq",
          "timestamp": 1626449467638
        },
        {
          "file_id": "18rdIPLRqUrIm5El0IMDk8pd4-34iwAHh",
          "timestamp": 1625588988908
        },
        {
          "file_id": "1Zxd0gF1x1vPR4gqQUsOADx6iI_KPktzr",
          "timestamp": 1625243963354
        },
        {
          "file_id": "16NVJN1t6qMrqsx-guXL7V491CYYA_ile",
          "timestamp": 1624588651913
        },
        {
          "file_id": "1kMjHd3M2dDnlegYKlt2A6w6Ckcc5FGRi",
          "timestamp": 1624546926039
        },
        {
          "file_id": "1a07n5r3GDqVqgcvB36t8FTfPL9H9LuuX",
          "timestamp": 1624488024401
        },
        {
          "file_id": "1LgQaLkIgTAMix0PrNiBc8DnHk66U324g",
          "timestamp": 1624467180657
        },
        {
          "file_id": "1DWQpm9DyYFhZTUL28PSCtUIugu7pZTTD",
          "timestamp": 1623879707760
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
