{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcYJIEwd3As"
      },
      "source": [
        "#### local run command\n",
        "`blaze run -c opt learning/brain/research/babelfish/colab:colab_notebook --define=babelfish_task=multimodal`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7ZcyyqZKJi"
      },
      "outputs": [],
      "source": [
        "import lingvo.compat as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import os\n",
        "\n",
        "from lingvo.core import py_utils\n",
        "from google3.learning.brain.research.babelfish import tokenizers\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import image_text_baselines as it_params\n",
        "from google3.learning.brain.research.babelfish.multimodal.params.experimental import nlu_baselines as nlu_params\n",
        "\n",
        "# from google3.pyglib import gfiler\n",
        "\n",
        "from google3.perftools.accelerators.xprof.api.colab import xprof\n",
        "\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZujlTGZZlK"
      },
      "outputs": [],
      "source": [
        "# mdl = it_params.ImageText2TextLMSmall()\n",
        "mdl = nlu_params.QNLIClassification()\n",
        "p = mdl.Task()\n",
        "\n",
        "# Note: We use the name as part of var/name scopes, you need to ensure that\n",
        "# the name here matches for checkpoints to load successfully.\n",
        "\n",
        "\n",
        "p.name = 'GLUETask'\n",
        "\n",
        "# if text2text:\n",
        "p.decoder.shared_emb.softmax.use_num_classes_major_weight = False\n",
        "p.encoder.shared_emb.softmax.use_num_classes_major_weight = False\n",
        "\n",
        "p.input = mdl.Train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CafizIxXQfa"
      },
      "outputs": [],
      "source": [
        "# We are going to use the global graph for this entire colab.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the Task.\n",
        "task = p.Instantiate()\n",
        "\n",
        "# Create variables by running FProp.\n",
        "_ = task.FPropDefaultTheta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcdhCnAGprFr"
      },
      "outputs": [],
      "source": [
        "# Create a new session and initialize all the variables.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mAMVdCJgUp9"
      },
      "outputs": [],
      "source": [
        "# Setup the checkpoint loading rules for OverrideVarsFromCheckpoints.\n",
        "loading_rules = [\n",
        "    (\n",
        "        \"(.*)\",  # Regexp match all variables in the ckpt.\n",
        "        \"%s\"     # Format string to use the saved var name as is.\n",
        "    )\n",
        "]\n",
        "ignore_rules = []  # No ignore rules, parse all saved vars.\n",
        "# ckpt_path = '/cns/tp-d/home/runzheyang/brain/rs=6.3/qnli.imagetext2textlm/train/ckpt-00010000'\n",
        "ckpt_path = '/cns/tp-d/home/runzheyang/brain/rs=6.3/qnli.text2textlm/train/ckpt-00010000'\n",
        "\n",
        "ckpts_loading_rules = {\n",
        "    ckpt_path: (loading_rules, ignore_rules)\n",
        "}\n",
        "\n",
        "# Load the saved checkpoint into the session.\n",
        "py_utils.OverrideVarsFromCheckpoints(\n",
        "    tf.all_variables(), ckpts_loading_rules)(sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFnb8MH-Yx0j"
      },
      "source": [
        "## Check examples from the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2dxcp9hG3m2"
      },
      "outputs": [],
      "source": [
        "mdl.TRAIN_BATCH_SIZE = 128\n",
        "mdl.EVAL_BATCH_SIZE = 128\n",
        "input_p = mdl.Train()\n",
        "\n",
        "input_gen = input_p.Instantiate()\n",
        "input_batch = input_gen.GetPreprocessedInputBatch()\n",
        "\n",
        "ids = input_batch.ids\n",
        "paddings = input_batch.paddings\n",
        "\n",
        "# encoder\n",
        "sources = py_utils.NestedMap(ids=ids, paddings=paddings)\n",
        "encoder_embeddings = task.encoder.FPropEmbeddings(task.theta.encoder, sources)\n",
        "encoder_outputs = task.encoder.FPropTransformerLayers(task.theta.encoder, \n",
        "                                                      encoder_embeddings)\n",
        "\n",
        "# decoder\n",
        "targets = py_utils.NestedMap(ids=ids, paddings=paddings)\n",
        "decoder_outputs = task.decoder.ComputePredictions(task.theta.decoder,\n",
        "                                                  encoder_outputs, targets)\n",
        "\n",
        "classifier_input = task._extract_classifier_input(paddings, decoder_outputs)\n",
        "\n",
        "predictions = task._apply_classifier(task.theta, classifier_input)\n",
        "\n",
        "# Notice that we are calling this with task.theta which ensures that we are\n",
        "# using the same variables which we have just loaded.\n",
        "fetches = py_utils.NestedMap(\n",
        "          {\"labels\": input_batch.labels,\n",
        "           \"sources\": sources,\n",
        "           \"encoder_embeddings\": encoder_embeddings,\n",
        "           \"encoder_outputs\": encoder_outputs,\n",
        "           \"decoder_outputs\": decoder_outputs,\n",
        "           \"classifier_input\": classifier_input,\n",
        "           \"predictions\":predictions})\n",
        "\n",
        "print(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vpa4uj44y_JM"
      },
      "outputs": [],
      "source": [
        "input_gen.Initialize(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-afJpQRCEAp"
      },
      "outputs": [],
      "source": [
        "test_output = sess.run(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZL4hirx_eil"
      },
      "outputs": [],
      "source": [
        "def pretty_print_examples(input_str, label, prediction):\n",
        "  index = input_str.find('sentence')\n",
        "  print(input_str[:index] + \"\\n\" + input_str[index:])\n",
        "  print(\"label: \" + (\"\\x1b[32mENTAIL\\x1b[0m\" if label == 1 else \"\\x1b[31mNOT ENTAIL\\x1b[0m\"))\n",
        "  print(\"prediction: \" + (\"\\x1b[32mENTAIL\\x1b[0m\" if prediction == 1 else \"\\x1b[31mNOT ENTAIL\\x1b[0m\"))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD0U9od6kB6W"
      },
      "outputs": [],
      "source": [
        "# check batch accuracy\n",
        "((test_output[\"labels\"].reshape(-1) - \n",
        "  np.argmax(test_output[\"predictions\"][\"probs\"], axis=1)) == 0).sum() / mdl.TRAIN_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR7w_4h5IUcS"
      },
      "outputs": [],
      "source": [
        "# check a few examples from training set\n",
        "for i in range(mdl.TRAIN_BATCH_SIZE):\n",
        "  pretty_print_examples(input_gen._vocabulary._decode(\n",
        "      [int(ids) for ids in test_output[\"sources\"][\"ids\"][i]]),\n",
        "      test_output[\"labels\"][i],\n",
        "      np.argmax(test_output[\"predictions\"][\"probs\"], axis=1)[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO6LxusTIKGV"
      },
      "outputs": [],
      "source": [
        "emb_out = test_output[\"encoder_embeddings\"][\"input_embs\"][test_output[\"encoder_embeddings\"][\"paddings\"]==0]\n",
        "emb_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP1O-uzLP11E"
      },
      "outputs": [],
      "source": [
        "enc_out = test_output[\"encoder_outputs\"][\"encoded\"][test_output[\"encoder_outputs\"][\"padding\"] == 0]\n",
        "enc_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIEEr4VmUmLL"
      },
      "outputs": [],
      "source": [
        "dec_out = test_output[\"decoder_outputs\"].reshape(-1, 512)\n",
        "dec_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a-vAwMHQOKR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy4eY1-7Qlmk"
      },
      "outputs": [],
      "source": [
        "def cov(X):\n",
        "    X = (X - X.mean(0))\n",
        "    return X.T.dot(X)/X.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZGeOI0xSlOP"
      },
      "outputs": [],
      "source": [
        "emb_cov = cov(emb_out)\n",
        "emb_eigvals, emb_eigvecs = np.linalg.eig(emb_cov)\n",
        "\n",
        "enc_cov = cov(enc_out)\n",
        "enc_eigvals, enc_eigvecs = np.linalg.eig(enc_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mQ52j7RVABS"
      },
      "outputs": [],
      "source": [
        "dec_cov = cov(dec_out)\n",
        "dec_eigvals, dec_eigvecs = np.linalg.eig(dec_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67uKAD9TSqwv"
      },
      "outputs": [],
      "source": [
        "# check if neural activity lies on a low-dimensional manifold\n",
        "top_k = 100\n",
        "plt.plot(np.arange(len(emb_eigvals))[:top_k], \n",
        "         np.cumsum(emb_eigvals[:top_k])/emb_eigvals.sum(), label=\"embedding\")\n",
        "plt.plot(np.arange(len(enc_eigvals))[:top_k], \n",
        "         np.cumsum(enc_eigvals[:top_k])/enc_eigvals.sum(), label=\"encoder output\")\n",
        "plt.plot(np.arange(len(enc_eigvals))[:top_k], \n",
        "         np.cumsum(dec_eigvals[:top_k])/dec_eigvals.sum(), label=\"decoder output\")\n",
        "plt.ylabel(\"variance explained\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89XsgZ5mTBG7"
      },
      "outputs": [],
      "source": [
        "len(np.unique(test_output[\"sources\"][\"ids\"].reshape(-1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGU3OzrhZBUj"
      },
      "source": [
        "## Check examples from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yuj1zLXYvbH"
      },
      "outputs": [],
      "source": [
        "# feeds = {\n",
        "#     'text': tf.placeholder(tf.string, shape=[1,])\n",
        "# }\n",
        "# input_batch = py_utils.NestedMap(encoder_inputs=feeds['text'], \n",
        "#                                  decoder_inputs=feeds['text'])\n",
        "\n",
        "mdl.TRAIN_BATCH_SIZE = 64\n",
        "mdl.EVAL_BATCH_SIZE = 64\n",
        "input_p = mdl.Test()\n",
        "\n",
        "input_gen = input_p.Instantiate()\n",
        "input_batch = input_gen.GetPreprocessedInputBatch()\n",
        "\n",
        "ids = input_batch.ids\n",
        "paddings = input_batch.paddings\n",
        "\n",
        "# encoder\n",
        "sources = py_utils.NestedMap(ids=ids, paddings=paddings)\n",
        "encoder_embeddings = task.encoder.FPropEmbeddings(task.theta.encoder, sources)\n",
        "encoder_outputs = task.encoder.FPropTransformerLayers(task.theta.encoder, \n",
        "                                                      encoder_embeddings)\n",
        "\n",
        "# decoder\n",
        "targets = py_utils.NestedMap(ids=ids, paddings=paddings)\n",
        "decoder_outputs = task.decoder.ComputePredictions(task.theta.decoder,\n",
        "                                                  encoder_outputs, targets)\n",
        "\n",
        "classifier_input = task._extract_classifier_input(paddings, decoder_outputs)\n",
        "\n",
        "predictions = task._apply_classifier(task.theta, classifier_input)\n",
        "\n",
        "# Notice that we are calling this with task.theta which ensures that we are\n",
        "# using the same variables which we have just loaded.\n",
        "fetches = py_utils.NestedMap(\n",
        "          {\"labels\": input_batch.labels,\n",
        "           \"sources\": sources,\n",
        "           \"encoder_embeddings\": encoder_embeddings,\n",
        "           \"encoder_outputs\": encoder_outputs,\n",
        "           \"decoder_outputs\": decoder_outputs,\n",
        "           \"classifier_input\": classifier_input,\n",
        "           \"predictions\":predictions})\n",
        "\n",
        "print(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2DvoaurYvbX"
      },
      "outputs": [],
      "source": [
        "input_gen.Initialize(sess)\n",
        "test_output = sess.run(fetches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJQBPKilklq7"
      },
      "outputs": [],
      "source": [
        "# check batch accuracy\n",
        "((test_output[\"labels\"].reshape(-1) - \n",
        "  np.argmax(test_output[\"predictions\"][\"probs\"], axis=1)) == 0).sum() / mdl.TRAIN_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KSu8S28Yvba"
      },
      "outputs": [],
      "source": [
        "# check a few examples from test set\n",
        "for i in range(mdl.TRAIN_BATCH_SIZE):\n",
        "  pretty_print_examples(input_gen._vocabulary._decode(\n",
        "      [int(ids) for ids in test_output[\"sources\"][\"ids\"][i]]),\n",
        "      test_output[\"labels\"][i],\n",
        "      np.argmax(test_output[\"predictions\"][\"probs\"], axis=1)[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12gIzDZdYvbc"
      },
      "outputs": [],
      "source": [
        "emb_out = test_output[\"encoder_embeddings\"][\"input_embs\"][test_output[\"encoder_embeddings\"][\"paddings\"]==0]\n",
        "emb_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP88gUonYvbd"
      },
      "outputs": [],
      "source": [
        "enc_out = test_output[\"encoder_outputs\"][\"encoded\"][test_output[\"encoder_outputs\"][\"padding\"] == 0]\n",
        "enc_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ9bhPweYvbf"
      },
      "outputs": [],
      "source": [
        "dec_out = test_output[\"decoder_outputs\"].reshape(-1, 512)\n",
        "dec_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gcqq_DLFYvbg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dvSyX0MYvbh"
      },
      "outputs": [],
      "source": [
        "def cov(X):\n",
        "    X = (X - X.mean(0))\n",
        "    return X.T.dot(X)/X.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFEEei2tYvbh"
      },
      "outputs": [],
      "source": [
        "emb_cov = cov(emb_out)\n",
        "emb_eigvals, emb_eigvecs = np.linalg.eig(emb_cov)\n",
        "\n",
        "enc_cov = cov(enc_out)\n",
        "enc_eigvals, enc_eigvecs = np.linalg.eig(enc_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2U3AUwfYvbi"
      },
      "outputs": [],
      "source": [
        "dec_cov = cov(dec_out)\n",
        "dec_eigvals, dec_eigvecs = np.linalg.eig(dec_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYL56jeqYvbj"
      },
      "outputs": [],
      "source": [
        "# check if neural activity lies on a low-dimensional manifold\n",
        "top_k = 100\n",
        "plt.plot(np.arange(len(emb_eigvals))[:top_k], \n",
        "         np.cumsum(emb_eigvals[:top_k])/emb_eigvals.sum(), label=\"embedding\")\n",
        "plt.plot(np.arange(len(enc_eigvals))[:top_k], \n",
        "         np.cumsum(enc_eigvals[:top_k])/enc_eigvals.sum(), label=\"encoder output\")\n",
        "plt.plot(np.arange(len(enc_eigvals))[:top_k], \n",
        "         np.cumsum(dec_eigvals[:top_k])/dec_eigvals.sum(), label=\"decoder output\")\n",
        "plt.ylabel(\"variance explained\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3lVpByeYvbk"
      },
      "outputs": [],
      "source": [
        "len(np.unique(test_output[\"sources\"][\"ids\"].reshape(-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZZ1jTNzZQma"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "QNLI inspection (local).ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "16NVJN1t6qMrqsx-guXL7V491CYYA_ile",
          "timestamp": 1630077354660
        },
        {
          "file_id": "1kMjHd3M2dDnlegYKlt2A6w6Ckcc5FGRi",
          "timestamp": 1624546926039
        },
        {
          "file_id": "1a07n5r3GDqVqgcvB36t8FTfPL9H9LuuX",
          "timestamp": 1624488024401
        },
        {
          "file_id": "1LgQaLkIgTAMix0PrNiBc8DnHk66U324g",
          "timestamp": 1624467180657
        },
        {
          "file_id": "1DWQpm9DyYFhZTUL28PSCtUIugu7pZTTD",
          "timestamp": 1623879707760
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
